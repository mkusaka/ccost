{
  "azure/gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "source": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "input_cost_per_token": 5e-08,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5e-09,
    "input_cost_per_token": 5e-08,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-pro": {
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure?pivots=azure-openai&tabs=global-standard-aoai%2Cstandard-chat-completions%2Cglobal-standard#gpt-5",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-chat-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-mini-2025-11-13": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2": {
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-chat": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-chat-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-pro": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "azure/gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_flex": 6.25e-08,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_flex": 6.25e-07,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_flex": 5e-06,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_flex": 6.25e-08,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_flex": 6.25e-07,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_flex": 5e-06,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_flex": 1.25e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_flex": 1.25e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_flex": 1e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_flex": 1.25e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_flex": 1.25e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_flex": 1e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "cache_read_input_token_cost_flex": 2.5e-09,
    "input_cost_per_token": 5e-08,
    "input_cost_per_token_flex": 2.5e-08,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_flex": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5e-09,
    "cache_read_input_token_cost_flex": 2.5e-09,
    "input_cost_per_token": 5e-08,
    "input_cost_per_token_flex": 2.5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_flex": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-pro": {
    "input_cost_per_token": 1.5e-05,
    "input_cost_per_token_batches": 7.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 6e-05,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-pro-2025-10-06": {
    "input_cost_per_token": 1.5e-05,
    "input_cost_per_token_batches": 7.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 6e-05,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api-2025-10-14": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.1": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.2-chat-latest": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-pro": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "openrouter/openai/gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "input_cost_per_token": 5e-08,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5.2": {
    "input_cost_per_image": 0,
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5.2-chat": {
    "input_cost_per_image": 0,
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5.2-pro": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000168,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  }
}

{
  "azure/gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "source": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "input_cost_per_token": 5e-08,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5e-09,
    "input_cost_per_token": 5e-08,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-pro": {
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure?pivots=azure-openai&tabs=global-standard-aoai%2Cstandard-chat-completions%2Cglobal-standard#gpt-5",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-chat-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-mini-2025-11-13": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2": {
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-chat": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-chat-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-pro": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "azure/gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "azure_ai/kimi-k2.5": {
    "input_cost_per_token": 6e-07,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 3e-06,
    "source": "https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/kimi-k2-5-now-in-microsoft-foundry/4492321",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "gemini-3-pro-image-preview": {
    "input_cost_per_image": 0.0011,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 65536,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.134,
    "output_cost_per_image_token": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://ai.google.dev/gemini-api/docs/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true,
    "input_cost_per_token_priority": 3.6e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "supports_service_tier": true
  },
  "gemini/gemini-3-pro-image-preview": {
    "input_cost_per_image": 0.0011,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "gemini",
    "max_input_tokens": 65536,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.134,
    "output_cost_per_image_token": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "rpm": 1000,
    "tpm": 4000000,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://ai.google.dev/gemini-api/docs/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini/gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_batches": 6e-06,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000,
    "input_cost_per_token_priority": 3.6e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "supports_service_tier": true
  },
  "gmi/google/gemini-3-pro-preview": {
    "input_cost_per_token": 2e-06,
    "litellm_provider": "gmi",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_flex": 6.25e-08,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_flex": 6.25e-07,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_flex": 5e-06,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_flex": 6.25e-08,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_flex": 6.25e-07,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_flex": 5e-06,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_flex": 1.25e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_flex": 1.25e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_flex": 1e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_flex": 1.25e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_flex": 1.25e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_flex": 1e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "cache_read_input_token_cost_flex": 2.5e-09,
    "input_cost_per_token": 5e-08,
    "input_cost_per_token_flex": 2.5e-08,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_flex": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5e-09,
    "cache_read_input_token_cost_flex": 2.5e-09,
    "input_cost_per_token": 5e-08,
    "input_cost_per_token_flex": 2.5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_flex": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-pro": {
    "input_cost_per_token": 1.5e-05,
    "input_cost_per_token_batches": 7.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 6e-05,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-pro-2025-10-06": {
    "input_cost_per_token": 1.5e-05,
    "input_cost_per_token_batches": 7.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 6e-05,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api-2025-10-14": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.1": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.2-chat-latest": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-pro": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "moonshot/kimi-k2.5": {
    "cache_read_input_token_cost": 1e-07,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "moonshot",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 3e-06,
    "source": "https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "moonshotai.kimi-k2.5": {
    "input_cost_per_token": 6e-07,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 3e-06,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "openrouter/google/gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "openrouter",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_batches": 6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "openrouter/moonshotai/kimi-k2.5": {
    "cache_read_input_token_cost": 1e-07,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 3e-06,
    "source": "https://openrouter.ai/moonshotai/kimi-k2.5",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "input_cost_per_token": 5e-08,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5.2": {
    "input_cost_per_image": 0,
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5.2-chat": {
    "input_cost_per_image": 0,
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "input_cost_per_token": 1.75e-06,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5.2-pro": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000168,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/gemini-3-pro-image-preview": {
    "input_cost_per_image": 0.0011,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 65536,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.134,
    "output_cost_per_image_token": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/3-pro-image"
  },
  "vertex_ai/gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "vertex_ai",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true,
    "input_cost_per_token_priority": 3.6e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "supports_service_tier": true
  }
}
